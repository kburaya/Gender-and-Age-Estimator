{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>user_1grams</th>\n",
       "      <th>user_2grams</th>\n",
       "      <th>user_3grams</th>\n",
       "      <th>avr_mentions</th>\n",
       "      <th>avr_punctuation</th>\n",
       "      <th>avr_text_size</th>\n",
       "      <th>avr_starts_with_capital</th>\n",
       "      <th>avr_ends_with_punctuation</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>50-64\\r\\r\\r\\r\\r\\n</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>2.148148</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MALE</td>\n",
       "      <td>50-64\\r\\r\\r\\r\\r\\n</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.563636</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MALE</td>\n",
       "      <td>18-24\\r\\r\\r\\r\\r\\n</td>\n",
       "      <td>0.753260</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.034102</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>3.477432</td>\n",
       "      <td>103.528586</td>\n",
       "      <td>0.676028</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35-49\\r\\r\\r\\r\\r\\n</td>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>1.207207</td>\n",
       "      <td>4.055055</td>\n",
       "      <td>135.671672</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.723724</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>1.231231</td>\n",
       "      <td>0.029029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MALE</td>\n",
       "      <td>35-49\\r\\r\\r\\r\\r\\n</td>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>0.302949</td>\n",
       "      <td>1.938338</td>\n",
       "      <td>82.536193</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>0.319035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex                age  user_1grams  user_2grams  user_3grams  \\\n",
       "0  FEMALE  50-64\\r\\r\\r\\r\\r\\n     0.425926     0.481481     0.546296   \n",
       "1    MALE  50-64\\r\\r\\r\\r\\r\\n     1.300000     1.472727     1.500000   \n",
       "2    MALE  18-24\\r\\r\\r\\r\\r\\n     0.753260     1.003009     1.034102   \n",
       "3  FEMALE  35-49\\r\\r\\r\\r\\r\\n     0.615616     0.824825     0.869870   \n",
       "4    MALE  35-49\\r\\r\\r\\r\\r\\n     0.695710     0.813673     0.820375   \n",
       "\n",
       "   avr_mentions  avr_punctuation  avr_text_size  avr_starts_with_capital  \\\n",
       "0      0.685185         2.148148      74.666667                 0.796296   \n",
       "1      1.200000         2.563636      88.636364                 0.236364   \n",
       "2      0.494483         3.477432     103.528586                 0.676028   \n",
       "3      1.207207         4.055055     135.671672                 0.853854   \n",
       "4      0.302949         1.938338      82.536193                 0.190349   \n",
       "\n",
       "   avr_ends_with_punctuation ...         WP  WP$       WRB         ,  \\\n",
       "0                   0.240741 ...   0.000000  0.0  0.000000  0.111111   \n",
       "1                   0.763636 ...   0.072727  0.0  0.000000  0.345455   \n",
       "2                   0.563691 ...   0.069208  0.0  0.057172  0.274824   \n",
       "3                   0.653654 ...   0.094094  0.0  0.090090  0.311311   \n",
       "4                   0.319035 ...   0.018767  0.0  0.056300  0.123324   \n",
       "\n",
       "          .         )         (         :         $   ''  \n",
       "0  0.888889  0.037037  0.037037  0.722222  0.000000  0.0  \n",
       "1  1.109091  0.090909  0.036364  0.727273  0.000000  0.0  \n",
       "2  1.338014  0.070211  0.034102  0.996991  0.000000  0.0  \n",
       "3  1.723724  0.030030  0.013013  1.231231  0.029029  0.0  \n",
       "4  0.428954  0.120643  0.069705  0.906166  0.013405  0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_features.csv', sep='\\t', index_col=0)\n",
    "data = pd.DataFrame(data)\n",
    "del data['Unnamed: 0.1']\n",
    "del data['Unnamed: 0.1.1']\n",
    "\n",
    "del data['user']\n",
    "data = data.fillna(0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1grams</th>\n",
       "      <th>user_2grams</th>\n",
       "      <th>user_3grams</th>\n",
       "      <th>avr_mentions</th>\n",
       "      <th>avr_punctuation</th>\n",
       "      <th>avr_text_size</th>\n",
       "      <th>avr_starts_with_capital</th>\n",
       "      <th>avr_ends_with_punctuation</th>\n",
       "      <th>avr_capitals</th>\n",
       "      <th>avr_words_count</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>2.148148</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.563636</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.753260</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.034102</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>3.477432</td>\n",
       "      <td>103.528586</td>\n",
       "      <td>0.676028</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>1.207207</td>\n",
       "      <td>4.055055</td>\n",
       "      <td>135.671672</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.723724</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>1.231231</td>\n",
       "      <td>0.029029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>0.302949</td>\n",
       "      <td>1.938338</td>\n",
       "      <td>82.536193</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>0.319035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_1grams  user_2grams  user_3grams  avr_mentions  avr_punctuation  \\\n",
       "0     0.425926     0.481481     0.546296      0.685185         2.148148   \n",
       "1     1.300000     1.472727     1.500000      1.200000         2.563636   \n",
       "2     0.753260     1.003009     1.034102      0.494483         3.477432   \n",
       "3     0.615616     0.824825     0.869870      1.207207         4.055055   \n",
       "4     0.695710     0.813673     0.820375      0.302949         1.938338   \n",
       "\n",
       "   avr_text_size  avr_starts_with_capital  avr_ends_with_punctuation  \\\n",
       "0      74.666667                 0.796296                   0.240741   \n",
       "1      88.636364                 0.236364                   0.763636   \n",
       "2     103.528586                 0.676028                   0.563691   \n",
       "3     135.671672                 0.853854                   0.653654   \n",
       "4      82.536193                 0.190349                   0.319035   \n",
       "\n",
       "   avr_capitals  avr_words_count ...         WP  WP$       WRB         ,  \\\n",
       "0             0         0.064815 ...   0.000000  0.0  0.000000  0.111111   \n",
       "1             0         0.172727 ...   0.072727  0.0  0.000000  0.345455   \n",
       "2             0         0.019057 ...   0.069208  0.0  0.057172  0.274824   \n",
       "3             0         0.017017 ...   0.094094  0.0  0.090090  0.311311   \n",
       "4             0         0.006702 ...   0.018767  0.0  0.056300  0.123324   \n",
       "\n",
       "          .         )         (         :         $   ''  \n",
       "0  0.888889  0.037037  0.037037  0.722222  0.000000  0.0  \n",
       "1  1.109091  0.090909  0.036364  0.727273  0.000000  0.0  \n",
       "2  1.338014  0.070211  0.034102  0.996991  0.000000  0.0  \n",
       "3  1.723724  0.030030  0.013013  1.231231  0.029029  0.0  \n",
       "4  0.428954  0.120643  0.069705  0.906166  0.013405  0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model for age\n",
    "age_data = data\n",
    "target = age_data['age']\n",
    "del age_data['age']\n",
    "del age_data['sex']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(age_data, target, test_size = 0.20, random_state = 23)\n",
    "\n",
    "age_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.431818181818\n"
     ]
    }
   ],
   "source": [
    "#build logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, Y_train)\n",
    "print(log_reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306818181818\n"
     ]
    }
   ],
   "source": [
    "#build SVM model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "print(svm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.420454545455\n",
      "[ 0.01290907  0.00426505  0.00792398  0.02921405  0.0112474   0.03671305\n",
      "  0.04076108  0.02531972  0.          0.01943468  0.01761619  0.01055004\n",
      "  0.02101547  0.02226786  0.01691095  0.02575962  0.02910839  0.02633465\n",
      "  0.02232317  0.01145657  0.00691787  0.01043156  0.01614302  0.03587614\n",
      "  0.09191612  0.00801864  0.009251    0.00270677  0.01116499  0.01963606\n",
      "  0.01715813  0.03799396  0.01158731  0.01221374  0.00960185  0.00579998\n",
      "  0.00984623  0.00591862  0.02871559  0.00409217  0.01015193  0.01636219\n",
      "  0.02334323  0.01172628  0.02021896  0.00228515  0.01377097  0.02357596\n",
      "  0.01709577  0.04817542  0.0174086   0.02222656  0.02088107  0.00665716]\n"
     ]
    }
   ],
   "source": [
    "#build GBM model\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, Y_train)\n",
    "print(gbm.score(X_test, Y_test))\n",
    "print(gbm.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_model.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbm, 'gbm_model.pkl', compress = 9)\n",
    "joblib.dump(svm, 'svm_model.pkl', compress = 9)\n",
    "joblib.dump(log_reg, 'log_model.pkl', compress = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM: ['25-34\\r\\n']\n",
      "SVM: ['35-49\\r\\n']\n",
      "LOG REG: ['35-49\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 1]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM: ['25-34\\r\\n']\n",
      "SVM: ['35-49\\r\\n']\n",
      "LOG REG: ['35-49\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 0]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1grams</th>\n",
       "      <th>user_2grams</th>\n",
       "      <th>user_3grams</th>\n",
       "      <th>avr_mentions</th>\n",
       "      <th>avr_punctuation</th>\n",
       "      <th>avr_text_size</th>\n",
       "      <th>avr_starts_with_capital</th>\n",
       "      <th>avr_ends_with_punctuation</th>\n",
       "      <th>avr_capitals</th>\n",
       "      <th>avr_words_count</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>2.148148</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.563636</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.753260</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.034102</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>3.477432</td>\n",
       "      <td>103.528586</td>\n",
       "      <td>0.676028</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>1.207207</td>\n",
       "      <td>4.055055</td>\n",
       "      <td>135.671672</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.723724</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>1.231231</td>\n",
       "      <td>0.029029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>0.302949</td>\n",
       "      <td>1.938338</td>\n",
       "      <td>82.536193</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>0.319035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_1grams  user_2grams  user_3grams  avr_mentions  avr_punctuation  \\\n",
       "0     0.425926     0.481481     0.546296      0.685185         2.148148   \n",
       "1     1.300000     1.472727     1.500000      1.200000         2.563636   \n",
       "2     0.753260     1.003009     1.034102      0.494483         3.477432   \n",
       "3     0.615616     0.824825     0.869870      1.207207         4.055055   \n",
       "4     0.695710     0.813673     0.820375      0.302949         1.938338   \n",
       "\n",
       "   avr_text_size  avr_starts_with_capital  avr_ends_with_punctuation  \\\n",
       "0      74.666667                 0.796296                   0.240741   \n",
       "1      88.636364                 0.236364                   0.763636   \n",
       "2     103.528586                 0.676028                   0.563691   \n",
       "3     135.671672                 0.853854                   0.653654   \n",
       "4      82.536193                 0.190349                   0.319035   \n",
       "\n",
       "   avr_capitals  avr_words_count ...         WP  WP$       WRB         ,  \\\n",
       "0             0         0.064815 ...   0.000000  0.0  0.000000  0.111111   \n",
       "1             0         0.172727 ...   0.072727  0.0  0.000000  0.345455   \n",
       "2             0         0.019057 ...   0.069208  0.0  0.057172  0.274824   \n",
       "3             0         0.017017 ...   0.094094  0.0  0.090090  0.311311   \n",
       "4             0         0.006702 ...   0.018767  0.0  0.056300  0.123324   \n",
       "\n",
       "          .         )         (         :         $   ''  \n",
       "0  0.888889  0.037037  0.037037  0.722222  0.000000  0.0  \n",
       "1  1.109091  0.090909  0.036364  0.727273  0.000000  0.0  \n",
       "2  1.338014  0.070211  0.034102  0.996991  0.000000  0.0  \n",
       "3  1.723724  0.030030  0.013013  1.231231  0.029029  0.0  \n",
       "4  0.428954  0.120643  0.069705  0.906166  0.013405  0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model for sex\n",
    "sex_data = data\n",
    "target = sex_data['sex']\n",
    "del sex_data['age']\n",
    "del sex_data['sex']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(age_data, target, test_size = 0.20, random_state = 23)\n",
    "\n",
    "sex_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590909090909\n"
     ]
    }
   ],
   "source": [
    "#build logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, Y_train)\n",
    "print(log_reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534090909091\n"
     ]
    }
   ],
   "source": [
    "#build SVM model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "print(svm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659090909091\n"
     ]
    }
   ],
   "source": [
    "#build GBM model\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, Y_train)\n",
    "print(gbm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must  match the input. Model n_features is 11 and  input n_features is 5 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-342c7809f1b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m\"GBM: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m\"SVM: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m\"LOG REG: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \"\"\"\n\u001b[1;32m-> 1498\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1499\u001b[0m         \u001b[0mdecisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1455\u001b[0m         \"\"\"\n\u001b[0;32m   1456\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         \u001b[1;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[1;31m# not doing input validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_init_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[1;34m\"\"\"Check input and compute prediction of ``init``. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    374\u001b[0m                              \u001b[1;34m\" match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                              \u001b[1;34m\" input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must  match the input. Model n_features is 11 and  input n_features is 5 "
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 1]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM: ['MALE']\n",
      "SVM: ['FEMALE']\n",
      "LOG REG: ['FEMALE']\n"
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 0]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
