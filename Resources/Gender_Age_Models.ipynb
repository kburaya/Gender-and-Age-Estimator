{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all nessesary libs and read/prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from numpy import arange\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_features.csv', sep='\\t', index_col=0)\n",
    "data = pd.DataFrame(data)\n",
    "del data['Unnamed: 0.1']\n",
    "del data['Unnamed: 0.1.1']\n",
    "del data['\\'\\'']\n",
    "data = data.drop(['sex', 'age', 'user_1grams', 'user_2grams', 'user_3grams'], axis = 1)\n",
    "data = data.fillna(0)\n",
    "ngrams_data = pd.read_csv('data_ngrams.csv', sep = '\\t')\n",
    "del ngrams_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>avr_mentions</th>\n",
       "      <th>avr_punctuation</th>\n",
       "      <th>avr_text_size</th>\n",
       "      <th>avr_starts_with_capital</th>\n",
       "      <th>avr_ends_with_punctuation</th>\n",
       "      <th>avr_capitals</th>\n",
       "      <th>avr_words_count</th>\n",
       "      <th>vocabulary_richness</th>\n",
       "      <th>CC</th>\n",
       "      <th>...</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4905cc7a1396110c1a635c4e7b023de2</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>2.148148</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6733b2957179358024cc5c493f28924a</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.563636</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9aa58b658935d017e0827d1b42e75596</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>3.477432</td>\n",
       "      <td>103.528586</td>\n",
       "      <td>0.676028</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>35.269122</td>\n",
       "      <td>1.347041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454904ba35745fd0499f229c4b3e851c</td>\n",
       "      <td>1.207207</td>\n",
       "      <td>4.055055</td>\n",
       "      <td>135.671672</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>24.653740</td>\n",
       "      <td>1.025025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.723724</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>1.231231</td>\n",
       "      <td>0.029029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4dc094fb37152396199cb951207bb75d</td>\n",
       "      <td>0.302949</td>\n",
       "      <td>1.938338</td>\n",
       "      <td>82.536193</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>0.319035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.013405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user  avr_mentions  avr_punctuation  \\\n",
       "0  4905cc7a1396110c1a635c4e7b023de2      0.685185         2.148148   \n",
       "1  6733b2957179358024cc5c493f28924a      1.200000         2.563636   \n",
       "2  9aa58b658935d017e0827d1b42e75596      0.494483         3.477432   \n",
       "3  454904ba35745fd0499f229c4b3e851c      1.207207         4.055055   \n",
       "4  4dc094fb37152396199cb951207bb75d      0.302949         1.938338   \n",
       "\n",
       "   avr_text_size  avr_starts_with_capital  avr_ends_with_punctuation  \\\n",
       "0      74.666667                 0.796296                   0.240741   \n",
       "1      88.636364                 0.236364                   0.763636   \n",
       "2     103.528586                 0.676028                   0.563691   \n",
       "3     135.671672                 0.853854                   0.653654   \n",
       "4      82.536193                 0.190349                   0.319035   \n",
       "\n",
       "   avr_capitals  avr_words_count  vocabulary_richness        CC    ...     \\\n",
       "0             0         0.064815             0.000000  0.388889    ...      \n",
       "1             0         0.172727             0.000000  0.600000    ...      \n",
       "2             0         0.019057            35.269122  1.347041    ...      \n",
       "3             0         0.017017            24.653740  1.025025    ...      \n",
       "4             0         0.006702             0.000000  0.549598    ...      \n",
       "\n",
       "        WDT        WP  WP$       WRB         ,         .         )         (  \\\n",
       "0  0.000000  0.000000    0  0.000000  0.111111  0.888889  0.037037  0.037037   \n",
       "1  0.000000  0.072727    0  0.000000  0.345455  1.109091  0.090909  0.036364   \n",
       "2  0.019057  0.069208    0  0.057172  0.274824  1.338014  0.070211  0.034102   \n",
       "3  0.026026  0.094094    0  0.090090  0.311311  1.723724  0.030030  0.013013   \n",
       "4  0.018767  0.018767    0  0.056300  0.123324  0.428954  0.120643  0.069705   \n",
       "\n",
       "          :         $  \n",
       "0  0.722222  0.000000  \n",
       "1  0.727273  0.000000  \n",
       "2  0.996991  0.000000  \n",
       "3  1.231231  0.029029  \n",
       "4  0.906166  0.013405  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>user_common_1grams</th>\n",
       "      <th>user_common_2grams</th>\n",
       "      <th>user_common_3grams</th>\n",
       "      <th>user_age_18_24_ngrams</th>\n",
       "      <th>user_age_25_34_ngrams</th>\n",
       "      <th>user_age_35_49_ngrams</th>\n",
       "      <th>user_age_50_64_ngrams</th>\n",
       "      <th>user_age_65_xx_ngrams</th>\n",
       "      <th>user_gender_male_ngrams</th>\n",
       "      <th>user_gender_female_ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4905cc7a1396110c1a635c4e7b023de2</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>50-64\\n</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>1.046296</td>\n",
       "      <td>1.138889</td>\n",
       "      <td>1.129630</td>\n",
       "      <td>1.092593</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>1.064815</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6733b2957179358024cc5c493f28924a</td>\n",
       "      <td>MALE</td>\n",
       "      <td>50-64\\n</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.854545</td>\n",
       "      <td>1.936364</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>2.009091</td>\n",
       "      <td>1.463636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9aa58b658935d017e0827d1b42e75596</td>\n",
       "      <td>MALE</td>\n",
       "      <td>18-24\\n</td>\n",
       "      <td>0.753260</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.034102</td>\n",
       "      <td>1.913741</td>\n",
       "      <td>1.688064</td>\n",
       "      <td>1.668004</td>\n",
       "      <td>1.605817</td>\n",
       "      <td>1.005015</td>\n",
       "      <td>1.715145</td>\n",
       "      <td>1.665998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454904ba35745fd0499f229c4b3e851c</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35-49\\n</td>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>1.059059</td>\n",
       "      <td>1.123123</td>\n",
       "      <td>1.194194</td>\n",
       "      <td>1.140140</td>\n",
       "      <td>0.794795</td>\n",
       "      <td>1.133133</td>\n",
       "      <td>1.201201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4dc094fb37152396199cb951207bb75d</td>\n",
       "      <td>MALE</td>\n",
       "      <td>35-49\\n</td>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>1.170241</td>\n",
       "      <td>1.276139</td>\n",
       "      <td>1.305630</td>\n",
       "      <td>1.223861</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>1.308311</td>\n",
       "      <td>1.252011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user     sex      age  user_common_1grams  \\\n",
       "0  4905cc7a1396110c1a635c4e7b023de2  FEMALE  50-64\\n            0.425926   \n",
       "1  6733b2957179358024cc5c493f28924a    MALE  50-64\\n            1.300000   \n",
       "2  9aa58b658935d017e0827d1b42e75596    MALE  18-24\\n            0.753260   \n",
       "3  454904ba35745fd0499f229c4b3e851c  FEMALE  35-49\\n            0.615616   \n",
       "4  4dc094fb37152396199cb951207bb75d    MALE  35-49\\n            0.695710   \n",
       "\n",
       "   user_common_2grams  user_common_3grams  user_age_18_24_ngrams  \\\n",
       "0            0.481481            0.546296               1.046296   \n",
       "1            1.472727            1.500000               1.854545   \n",
       "2            1.003009            1.034102               1.913741   \n",
       "3            0.824825            0.869870               1.059059   \n",
       "4            0.813673            0.820375               1.170241   \n",
       "\n",
       "   user_age_25_34_ngrams  user_age_35_49_ngrams  user_age_50_64_ngrams  \\\n",
       "0               1.138889               1.129630               1.092593   \n",
       "1               1.936364               1.954545               2.009091   \n",
       "2               1.688064               1.668004               1.605817   \n",
       "3               1.123123               1.194194               1.140140   \n",
       "4               1.276139               1.305630               1.223861   \n",
       "\n",
       "   user_age_65_xx_ngrams  user_gender_male_ngrams  user_gender_female_ngrams  \n",
       "0               0.796296                 1.064815                   1.222222  \n",
       "1               1.463636                 2.000000                   1.945455  \n",
       "2               1.005015                 1.715145                   1.665998  \n",
       "3               0.794795                 1.133133                   1.201201  \n",
       "4               0.813673                 1.308311                   1.252011  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_data = ngrams_data.drop(['avr_mentions', 'avr_punctuation',\n",
    "       'avr_text_size', 'avr_starts_with_capital', 'avr_ends_with_punctuation',\n",
    "       'avr_capitals', 'avr_words_count', 'vocabulary_richness'], axis = 1)\n",
    "ngrams_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>user_common_1grams</th>\n",
       "      <th>user_common_2grams</th>\n",
       "      <th>user_common_3grams</th>\n",
       "      <th>user_age_18_24_ngrams</th>\n",
       "      <th>user_age_25_34_ngrams</th>\n",
       "      <th>user_age_35_49_ngrams</th>\n",
       "      <th>user_age_50_64_ngrams</th>\n",
       "      <th>...</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4905cc7a1396110c1a635c4e7b023de2</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>50-64\\n</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>1.046296</td>\n",
       "      <td>1.138889</td>\n",
       "      <td>1.129630</td>\n",
       "      <td>1.092593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6733b2957179358024cc5c493f28924a</td>\n",
       "      <td>MALE</td>\n",
       "      <td>50-64\\n</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.854545</td>\n",
       "      <td>1.936364</td>\n",
       "      <td>1.954545</td>\n",
       "      <td>2.009091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9aa58b658935d017e0827d1b42e75596</td>\n",
       "      <td>MALE</td>\n",
       "      <td>18-24\\n</td>\n",
       "      <td>0.753260</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.034102</td>\n",
       "      <td>1.913741</td>\n",
       "      <td>1.688064</td>\n",
       "      <td>1.668004</td>\n",
       "      <td>1.605817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454904ba35745fd0499f229c4b3e851c</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35-49\\n</td>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>1.059059</td>\n",
       "      <td>1.123123</td>\n",
       "      <td>1.194194</td>\n",
       "      <td>1.140140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.723724</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>1.231231</td>\n",
       "      <td>0.029029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4dc094fb37152396199cb951207bb75d</td>\n",
       "      <td>MALE</td>\n",
       "      <td>35-49\\n</td>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>1.170241</td>\n",
       "      <td>1.276139</td>\n",
       "      <td>1.305630</td>\n",
       "      <td>1.223861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.013405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user     sex      age  user_common_1grams  \\\n",
       "0  4905cc7a1396110c1a635c4e7b023de2  FEMALE  50-64\\n            0.425926   \n",
       "1  6733b2957179358024cc5c493f28924a    MALE  50-64\\n            1.300000   \n",
       "2  9aa58b658935d017e0827d1b42e75596    MALE  18-24\\n            0.753260   \n",
       "3  454904ba35745fd0499f229c4b3e851c  FEMALE  35-49\\n            0.615616   \n",
       "4  4dc094fb37152396199cb951207bb75d    MALE  35-49\\n            0.695710   \n",
       "\n",
       "   user_common_2grams  user_common_3grams  user_age_18_24_ngrams  \\\n",
       "0            0.481481            0.546296               1.046296   \n",
       "1            1.472727            1.500000               1.854545   \n",
       "2            1.003009            1.034102               1.913741   \n",
       "3            0.824825            0.869870               1.059059   \n",
       "4            0.813673            0.820375               1.170241   \n",
       "\n",
       "   user_age_25_34_ngrams  user_age_35_49_ngrams  user_age_50_64_ngrams  \\\n",
       "0               1.138889               1.129630               1.092593   \n",
       "1               1.936364               1.954545               2.009091   \n",
       "2               1.688064               1.668004               1.605817   \n",
       "3               1.123123               1.194194               1.140140   \n",
       "4               1.276139               1.305630               1.223861   \n",
       "\n",
       "     ...          WDT        WP  WP$       WRB         ,         .         )  \\\n",
       "0    ...     0.000000  0.000000    0  0.000000  0.111111  0.888889  0.037037   \n",
       "1    ...     0.000000  0.072727    0  0.000000  0.345455  1.109091  0.090909   \n",
       "2    ...     0.019057  0.069208    0  0.057172  0.274824  1.338014  0.070211   \n",
       "3    ...     0.026026  0.094094    0  0.090090  0.311311  1.723724  0.030030   \n",
       "4    ...     0.018767  0.018767    0  0.056300  0.123324  0.428954  0.120643   \n",
       "\n",
       "          (         :         $  \n",
       "0  0.037037  0.722222  0.000000  \n",
       "1  0.036364  0.727273  0.000000  \n",
       "2  0.034102  0.996991  0.000000  \n",
       "3  0.013013  1.231231  0.029029  \n",
       "4  0.069705  0.906166  0.013405  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_data = ngrams_data.merge(data, on = 'user')\n",
    "\n",
    "X = users_data.drop(['user', 'sex', 'age'], axis = 1)\n",
    "Yage = users_data['age']\n",
    "Ysex = users_data['sex']\n",
    "\n",
    "users_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of average words for every age category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b16a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b1a8b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "p = plt.subplot()\n",
    "classes = np.arange(6)\n",
    "width = 0.2\n",
    "\n",
    "for i in range(1, 6):\n",
    "    if i == 1: \n",
    "        age = '18-24\\n'\n",
    "    elif i == 2: \n",
    "        age = '25-34\\n'\n",
    "    elif i == 3: \n",
    "        age = '35-49\\n'\n",
    "    elif i == 4: \n",
    "        age = '50-64\\n'\n",
    "    elif i == 5:\n",
    "        age = '65-xx\\n'\n",
    "        \n",
    "    p.bar(i - 1, users_data[users_data['age'] == age]['user_age_18_24_ngrams'].mean(), width, \n",
    "            color = 'b', label = '18-24' if i == 1 else '')\n",
    "    p.bar(i - 0.8, users_data[users_data['age'] == age]['user_age_25_34_ngrams'].mean(), width, \n",
    "            color = 'r', label = '25-34' if i == 1 else '')\n",
    "    p.bar(i - 0.6, users_data[users_data['age'] == age]['user_age_35_49_ngrams'].mean(), width, \n",
    "            color = 'y', label = '35-49' if i == 1 else '')\n",
    "    p.bar(i - 0.4, users_data[users_data['age'] == age]['user_age_50_64_ngrams'].mean(), width, \n",
    "            color = 'g', label = '50-64' if i == 1 else '')\n",
    "    p.bar(i -0.2 , users_data[users_data['age'] == age]['user_age_65_xx_ngrams'].mean(), width, \n",
    "            color = 'maroon', label = '65-xx' if i == 1 else '')\n",
    "\n",
    "\n",
    "p.set_xticks(classes + width)\n",
    "p.set_xticklabels(('18-24', '25-34', '35-49', '50-64', '65-xx'))\n",
    "p.legend(borderpad = 0.5, prop={'size':10}, loc='upper center')\n",
    "plt.show()\n",
    "plt.savefig('plots/user_age_ngrams.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See inside age ngrams features and build some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ngrams Features] Logistic Regression accuracy-Score for AGE: 0.705\n",
      "[Ngrams Features] Logistic Regression accuracy-Score for GENDER 0.898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GENDER_model.pkl',\n",
       " 'GENDER_model.pkl_01.npy',\n",
       " 'GENDER_model.pkl_02.npy',\n",
       " 'GENDER_model.pkl_03.npy',\n",
       " 'GENDER_model.pkl_04.npy']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngrams_train = X[['user_common_1grams', 'user_common_2grams', 'user_common_3grams',\n",
    "       'user_age_18_24_ngrams', 'user_age_25_34_ngrams',\n",
    "       'user_age_35_49_ngrams', 'user_age_50_64_ngrams',\n",
    "       'user_age_65_xx_ngrams', 'user_gender_male_ngrams',\n",
    "       'user_gender_female_ngrams']]\n",
    "\n",
    "# split data for AGE\n",
    "X = pd.DataFrame(X)\n",
    "Xage_train, Xage_test, Yage_train, Yage_test = train_test_split(X_ngrams_train, Yage, \n",
    "                                                                test_size = 0.2, random_state = 23)\n",
    "\n",
    "# split data for SEX\n",
    "Xsex_train, Xsex_test, Ysex_train, Ysex_test = train_test_split(X_ngrams_train, Ysex, \n",
    "                                                                test_size = 0.2, random_state = 23)\n",
    "\n",
    "# build logistic regression model\n",
    "# AGE\n",
    "log_model_age_ngrams = LogisticRegression()\n",
    "log_model_age_ngrams.fit(Xage_train, Yage_train)\n",
    "accuracy_age_ngrams = accuracy_score(Yage_test, log_model_age_ngrams.predict(Xage_test))\n",
    "print ('[Ngrams Features] Logistic Regression accuracy-Score for AGE: %.3f' % accuracy_age_ngrams)\n",
    "\n",
    "# SEX\n",
    "log_model_sex_ngrams = LogisticRegression()\n",
    "log_model_sex_ngrams.fit(Xsex_train, Ysex_train)\n",
    "predict = log_model_sex_ngrams.predict(Xsex_test)\n",
    "accuracy_sex_ngrams = accuracy_score(Ysex_test, log_model_sex_ngrams.predict(Xsex_test))\n",
    "print ('[Ngrams Features] Logistic Regression accuracy-Score for GENDER %.3f' % accuracy_sex_ngrams)\n",
    "\n",
    "joblib.dump(log_model_age_ngrams, 'AGE_model.pkl')\n",
    "joblib.dump(log_model_sex_ngrams, 'GENDER_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_common_1grams  user_common_2grams  user_common_3grams  \\\n",
      "98             0.688000            0.895000            0.978000   \n",
      "285            0.754167            0.850000            0.862500   \n",
      "262            0.675082            0.783754            0.810099   \n",
      "147            0.784000            0.977000            0.992000   \n",
      "158            1.164286            1.278571            1.278571   \n",
      "414            0.659722            0.725694            0.767361   \n",
      "323            0.560043            0.669501            0.686504   \n",
      "344            0.775641            0.961538            1.002137   \n",
      "4              0.695710            0.813673            0.820375   \n",
      "57             0.737681            0.918841            0.952174   \n",
      "89             0.450935            0.500000            0.532710   \n",
      "395            1.462963            1.648148            1.666667   \n",
      "123            0.487680            0.551335            0.562628   \n",
      "422            0.727000            1.015000            1.082000   \n",
      "389            0.911528            1.199732            1.239946   \n",
      "337            0.872754            1.149701            1.221557   \n",
      "1              1.300000            1.472727            1.500000   \n",
      "41             1.159664            1.365546            1.394958   \n",
      "433            2.917647            3.129412            3.164706   \n",
      "73             0.476673            0.579108            0.633874   \n",
      "167            0.825455            1.010909            1.038182   \n",
      "409            0.604317            0.732614            0.758993   \n",
      "12             1.290448            1.569201            1.619883   \n",
      "365            0.707746            0.821596            0.832160   \n",
      "65             0.723000            0.942000            0.984000   \n",
      "384            0.652959            0.861585            0.926780   \n",
      "90             0.756000            0.980000            1.008000   \n",
      "304            1.707143            1.967857            2.007143   \n",
      "32             0.596035            0.690211            0.750929   \n",
      "428            0.640044            0.752735            0.772429   \n",
      "..                  ...                 ...                 ...   \n",
      "194            0.728000            0.892000            0.913000   \n",
      "275            0.585000            0.757000            0.769000   \n",
      "403            0.960000            1.104444            1.151111   \n",
      "121            1.789474            2.036842            2.084211   \n",
      "294            0.716000            0.924000            0.950000   \n",
      "81             1.200000            1.300000            1.300000   \n",
      "210            0.733000            0.904000            0.925000   \n",
      "29             0.385947            0.464358            0.491853   \n",
      "162            0.661000            0.805000            0.827000   \n",
      "430            0.618852            0.659836            0.672131   \n",
      "27             0.671412            0.819692            0.841044   \n",
      "367            0.537634            0.580645            0.580645   \n",
      "133            1.385246            1.475410            1.483607   \n",
      "168            0.219429            0.245714            0.256000   \n",
      "8              0.529000            0.617000            0.627000   \n",
      "383            0.770771            0.967968            0.983984   \n",
      "290            0.649793            0.826446            0.849174   \n",
      "423            0.296178            0.334395            0.334395   \n",
      "93             1.370968            1.580645            1.580645   \n",
      "45             0.813000            1.061000            1.092000   \n",
      "252            0.620061            0.795339            0.826748   \n",
      "14             0.752000            0.906000            0.936000   \n",
      "146            2.169643            2.482143            2.598214   \n",
      "392            0.703704            0.915916            0.954955   \n",
      "84             0.805785            0.898760            0.915289   \n",
      "358            0.752000            0.992000            1.021000   \n",
      "356            0.933908            1.097701            1.112069   \n",
      "300            0.688161            0.918605            0.951374   \n",
      "132            0.732000            0.922000            0.942000   \n",
      "373            0.524000            0.617000            0.662000   \n",
      "\n",
      "     user_age_18_24_ngrams  user_age_25_34_ngrams  user_age_35_49_ngrams  \\\n",
      "98                1.375000               1.469000               1.509000   \n",
      "285               1.325000               1.470833               1.445833   \n",
      "262               1.442371               1.639956               1.544457   \n",
      "147               1.754000               1.937000               2.005000   \n",
      "158               1.935714               2.035714               2.107143   \n",
      "414               1.184028               1.298611               1.399306   \n",
      "323               1.213603               1.412327               1.306057   \n",
      "344               2.480769               1.912393               1.855769   \n",
      "4                 1.170241               1.276139               1.305630   \n",
      "57                1.398551               1.507246               1.437681   \n",
      "89                1.656542               1.747664               1.724299   \n",
      "395               2.166667               2.203704               2.314815   \n",
      "123               1.054415               1.137577               1.155031   \n",
      "422               1.540000               1.621000               1.667000   \n",
      "389               1.943700               1.878016               1.872654   \n",
      "337               1.703593               1.869760               1.785928   \n",
      "1                 1.854545               1.936364               1.954545   \n",
      "41                1.726891               1.873950               1.831933   \n",
      "433               4.576471               4.776471               4.788235   \n",
      "73                1.021298               1.140974               1.057809   \n",
      "167               1.409091               1.500000               1.565455   \n",
      "409               0.984412               1.080336               1.040767   \n",
      "12                2.489279               2.721248               2.799220   \n",
      "365               1.665493               1.744131               1.800469   \n",
      "65                1.441000               1.540000               1.550000   \n",
      "384               1.349047               1.485456               1.419258   \n",
      "90                1.712000               1.828000               1.873000   \n",
      "304               3.035714               3.582143               3.585714   \n",
      "32                1.096654               1.201983               1.278810   \n",
      "428               1.150985               1.223195               1.324945   \n",
      "..                     ...                    ...                    ...   \n",
      "194               1.589000               1.703000               1.766000   \n",
      "275               1.271000               1.410000               1.303000   \n",
      "403               1.640000               1.813333               1.744444   \n",
      "121               2.889474               3.015789               3.100000   \n",
      "294               1.650000               1.829000               1.744000   \n",
      "81                2.266667               2.466667               2.533333   \n",
      "210               1.523000               1.663000               1.752000   \n",
      "29                0.705703               0.817719               0.757637   \n",
      "162               1.469000               1.623000               1.667000   \n",
      "430               1.377049               1.512295               1.733607   \n",
      "27                1.192171               1.284698               1.357058   \n",
      "367               1.107527               1.145161               1.188172   \n",
      "133               2.336066               2.360656               2.475410   \n",
      "168               0.586286               0.648000               0.796571   \n",
      "8                 1.028000               1.225000               1.138000   \n",
      "383               1.699700               1.833834               1.894895   \n",
      "290               1.421488               1.543388               1.528926   \n",
      "423               0.748408               0.837580               0.780255   \n",
      "93                2.112903               2.209677               2.354839   \n",
      "45                2.410000               2.215000               2.265000   \n",
      "252               1.313070               1.427558               1.469098   \n",
      "14                1.753000               1.886000               1.939000   \n",
      "146               3.205357               3.357143               3.446429   \n",
      "392               1.377377               1.516517               1.459459   \n",
      "84                1.297521               1.402893               1.508264   \n",
      "358               1.801000               1.941000               1.966000   \n",
      "356               1.485632               1.683908               1.632184   \n",
      "300               1.270613               1.400634               1.364693   \n",
      "132               1.556000               1.727000               1.657000   \n",
      "373               0.973000               1.176000               1.087000   \n",
      "\n",
      "     user_age_50_64_ngrams  user_age_65_xx_ngrams  user_gender_male_ngrams  \\\n",
      "98                1.419000               0.951000                 1.454000   \n",
      "285               1.641667               0.979167                 1.558333   \n",
      "262               1.461032               0.944018                 1.519210   \n",
      "147               1.919000               1.128000                 1.979000   \n",
      "158               2.178571               1.542857                 2.114286   \n",
      "414               1.201389               0.916667                 1.354167   \n",
      "323               1.248672               0.787460                 1.299681   \n",
      "344               1.817308               1.135684                 1.995726   \n",
      "4                 1.223861               0.813673                 1.308311   \n",
      "57                1.369565               0.917391                 1.472464   \n",
      "89                1.182243               0.941589                 1.841121   \n",
      "395               2.259259               1.851852                 2.259259   \n",
      "123               1.332649               0.736140                 1.138604   \n",
      "422               1.542000               1.018000                 1.608000   \n",
      "389               1.788204               1.175603                 1.872654   \n",
      "337               1.745509               1.175150                 1.769461   \n",
      "1                 2.009091               1.463636                 2.000000   \n",
      "41                1.789916               1.302521                 1.831933   \n",
      "433               4.976471               3.682353                 4.764706   \n",
      "73                1.021298               0.690669                 1.054767   \n",
      "167               1.505455               1.023636                 1.549091   \n",
      "409               1.031175               0.702638                 1.071942   \n",
      "12                2.654971               1.693957                 2.785575   \n",
      "365               1.644366               1.068075                 1.811033   \n",
      "65                1.482000               0.947000                 1.516000   \n",
      "384               1.364092               0.880642                 1.390171   \n",
      "90                1.741000               1.087000                 1.848000   \n",
      "304               3.489286               2.214286                 3.596429   \n",
      "32                1.136307               0.745973                 1.258984   \n",
      "428               1.252735               0.861050                 1.261488   \n",
      "..                     ...                    ...                      ...   \n",
      "194               1.639000               1.033000                 1.737000   \n",
      "275               1.267000               0.811000                 1.378000   \n",
      "403               1.737778               1.237778                 1.775556   \n",
      "121               3.173684               2.178947                 3.057895   \n",
      "294               1.680000               1.020000                 1.744000   \n",
      "81                2.400000               1.966667                 2.466667   \n",
      "210               1.636000               0.980000                 1.740000   \n",
      "29                0.716904               0.519348                 0.764766   \n",
      "162               1.545000               0.939000                 1.586000   \n",
      "430               1.348361               1.024590                 1.651639   \n",
      "27                1.311981               0.908660                 1.288256   \n",
      "367               1.043011               0.784946                 1.129032   \n",
      "133               2.327869               1.754098                 2.442623   \n",
      "168               0.505143               0.385143                 0.677714   \n",
      "8                 1.095000               0.725000                 1.195000   \n",
      "383               1.765766               1.077077                 1.825826   \n",
      "290               1.797521               0.926653                 1.506198   \n",
      "423               0.694268               0.535032                 0.824841   \n",
      "93                2.080645               1.774194                 2.225806   \n",
      "45                2.137000               1.191000                 2.313000   \n",
      "252               1.354610               0.848024                 1.356636   \n",
      "14                1.840000               1.102000                 1.886000   \n",
      "146               3.321429               2.535714                 3.357143   \n",
      "392               1.424424               0.897898                 1.463463   \n",
      "84                1.324380               0.983471                 1.452479   \n",
      "358               1.834000               1.113000                 1.985000   \n",
      "356               1.586207               1.091954                 1.666667   \n",
      "300               1.325581               0.883721                 1.389006   \n",
      "132               1.578000               0.990000                 1.681000   \n",
      "373               1.043000               0.652000                 1.150000   \n",
      "\n",
      "     user_gender_female_ngrams  \n",
      "98                    1.537000  \n",
      "285                   1.420833  \n",
      "262                   1.668496  \n",
      "147                   1.962000  \n",
      "158                   2.100000  \n",
      "414                   1.263889  \n",
      "323                   1.413390  \n",
      "344                   1.863248  \n",
      "4                     1.252011  \n",
      "57                    1.460870  \n",
      "89                    1.563084  \n",
      "395                   2.277778  \n",
      "123                   1.274127  \n",
      "422                   1.689000  \n",
      "389                   1.912869  \n",
      "337                   1.889222  \n",
      "1                     1.945455  \n",
      "41                    1.857143  \n",
      "433                   4.941176  \n",
      "73                    1.150101  \n",
      "167                   1.525455  \n",
      "409                   1.028777  \n",
      "12                    2.725146  \n",
      "365                   1.730047  \n",
      "65                    1.567000  \n",
      "384                   1.501505  \n",
      "90                    1.845000  \n",
      "304                   3.546429  \n",
      "32                    1.177200  \n",
      "428                   1.327133  \n",
      "..                         ...  \n",
      "194                   1.720000  \n",
      "275                   1.280000  \n",
      "403                   1.791111  \n",
      "121                   3.205263  \n",
      "294                   1.826000  \n",
      "81                    2.600000  \n",
      "210                   1.647000  \n",
      "29                    0.804481  \n",
      "162                   1.697000  \n",
      "430                   1.528689  \n",
      "27                    1.367734  \n",
      "367                   1.198925  \n",
      "133                   2.475410  \n",
      "168                   0.742857  \n",
      "8                     1.124000  \n",
      "383                   1.909910  \n",
      "290                   1.680785  \n",
      "423                   0.761146  \n",
      "93                    2.338710  \n",
      "45                    2.198000  \n",
      "252                   1.525836  \n",
      "14                    1.980000  \n",
      "146                   3.517857  \n",
      "392                   1.515516  \n",
      "84                    1.429752  \n",
      "358                   1.905000  \n",
      "356                   1.600575  \n",
      "300                   1.384778  \n",
      "132                   1.667000  \n",
      "373                   1.027000  \n",
      "\n",
      "[348 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(np.array(Ysex_test), np.array(log_model_sex_ngrams.predict(Xsex_test)))\n",
    "print(Xsex_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_common_1grams', 'user_common_2grams', 'user_common_3grams',\n",
       "       'user_age_18_24_ngrams', 'user_age_25_34_ngrams',\n",
       "       'user_age_35_49_ngrams', 'user_age_50_64_ngrams',\n",
       "       'user_age_65_xx_ngrams', 'user_gender_male_ngrams',\n",
       "       'user_gender_female_ngrams', 'avr_mentions', 'avr_punctuation',\n",
       "       'avr_text_size', 'avr_starts_with_capital', 'avr_ends_with_punctuation',\n",
       "       'avr_capitals', 'avr_words_count', 'vocabulary_richness', 'CC', 'CD',\n",
       "       'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS',\n",
       "       'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP',\n",
       "       'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP',\n",
       "       'WP$', 'WRB', ',', '.', ')', '(', ':', '$'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ngrams Features] GBM accuracy-Score for AGE: 0.679\n",
      "[Ngrams Features] GBM accuracy-Score for GENDER: 0.695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GENDER_model.pkl',\n",
       " 'GENDER_model.pkl_01.npy',\n",
       " 'GENDER_model.pkl_02.npy',\n",
       " 'GENDER_model.pkl_03.npy',\n",
       " 'GENDER_model.pkl_04.npy']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build GBM model\n",
    "# AGE\n",
    "GBM_model_age_ngrams = GradientBoostingClassifier()\n",
    "GBM_model_age_ngrams.fit(Xage_train, Yage_train)\n",
    "accuracy_gbm_age_ngrams = accuracy_score(Yage_test, GBM_model_age_ngrams.predict(Xage_test))\n",
    "print('[Ngrams Features] GBM accuracy-Score for AGE: %.3f' % accuracy_gbm_age_ngrams)\n",
    "\n",
    "# SEX\n",
    "GBM_model_sex_ngrams = GradientBoostingClassifier()\n",
    "GBM_model_sex_ngrams.fit(Xsex_train, Ysex_train)\n",
    "accuracy_gbm_sex_ngrams = accuracy_score(Ysex_test, GBM_model_sex_ngrams.predict(Xsex_test))\n",
    "print('[Ngrams Features] GBM accuracy-Score for GENDER: %.3f' % accuracy_gbm_sex_ngrams)\n",
    "\n",
    "joblib.dump(log_model_age_ngrams, 'AGE_model.pkl')\n",
    "joblib.dump(log_model_sex_ngrams, 'GENDER_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ngrams Features] SVC accuracy-Score for AGE: 0.625\n",
      "[Ngrams Features] SVC accuracy-Score for GENDER: 0.545\n"
     ]
    }
   ],
   "source": [
    "# Build SVC model\n",
    "SVC_model_age_ngrams = SVC()\n",
    "SVC_model_age_ngrams.fit(Xage_train, Yage_train)\n",
    "accuracy_svc_age_ngrams = accuracy_score(Yage_test, SVC_model_age_ngrams.predict(Xage_test))\n",
    "print('[Ngrams Features] SVC accuracy-Score for AGE: %.3f' % accuracy_gbm_age_ngrams)\n",
    "\n",
    "# SEX\n",
    "SVC_model_sex_ngrams = SVC()\n",
    "SVC_model_sex_ngrams.fit(Xsex_train, Ysex_train)\n",
    "accuracy_svc_sex_ngrams = accuracy_score(Ysex_test, SVC_model_sex_ngrams.predict(Xsex_test))\n",
    "print('[Ngrams Features] SVC accuracy-Score for GENDER: %.3f' % accuracy_svc_sex_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b019518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b334f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "p = plt.subplot()\n",
    "classes = np.arange(2)\n",
    "width = 0.5\n",
    "\n",
    "for i in range(1, 3):\n",
    "    if i == 1: \n",
    "        gender = 'MALE'\n",
    "    elif i == 2: \n",
    "        gender = 'FEMALE'\n",
    "        \n",
    "    p.bar(i - 1, users_data[users_data['sex'] == gender]['user_gender_female_ngrams'].mean(), width, \n",
    "            color = 'b', label = 'female' if i == 1 else '')\n",
    "    p.bar(i - 0.5, users_data[users_data['sex'] == gender]['user_gender_male_ngrams'].mean(), width, \n",
    "            color = 'r', label = 'male' if i == 1 else '')\n",
    "\n",
    "\n",
    "p.set_xticks(classes + width)\n",
    "p.set_xticklabels(('male', 'female'))\n",
    "p.legend(borderpad = 0.5, prop={'size':8}, loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('plots/user_gender_ngrams.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see inside textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Postags Features] Logistic Regression accuracy-Score for AGE: 0.432\n",
      "[Postags Features] Logistic Regression accuracy-Score for GENDER 0.591\n"
     ]
    }
   ],
   "source": [
    "X_postags = X.drop(['user_age_18_24_ngrams', 'user_age_25_34_ngrams',\n",
    "       'user_age_35_49_ngrams', 'user_age_50_64_ngrams',\n",
    "       'user_age_65_xx_ngrams', 'user_gender_male_ngrams',\n",
    "       'user_gender_female_ngrams'], axis = 1)\n",
    "\n",
    "# split data for AGE\n",
    "X = pd.DataFrame(X)\n",
    "Xage_train, Xage_test, Yage_train, Yage_test = train_test_split(X_postags, Yage, \n",
    "                                                                test_size = 0.20, random_state = 23)\n",
    "\n",
    "# split data for SEX\n",
    "Xsex_train, Xsex_test, Ysex_train, Ysex_test = train_test_split(X_postags, Ysex, \n",
    "                                                                test_size = 0.20, random_state = 23)\n",
    "\n",
    "# build logistic regression model for textual features\n",
    "# AGE\n",
    "log_model_age_postags = LogisticRegression()\n",
    "log_model_age_postags.fit(Xage_train, Yage_train)\n",
    "accuracy_age_postags = accuracy_score(Yage_test, log_model_age_postags.predict(Xage_test))\n",
    "print ('[Postags Features] Logistic Regression accuracy-Score for AGE: %.3f' % accuracy_age_postags)\n",
    "b\n",
    "# SEX\n",
    "log_model_sex_postags = LogisticRegression()\n",
    "log_model_sex_postags.fit(Xsex_train, Ysex_train)\n",
    "predict = log_model_sex_postags.predict(Xsex_test)\n",
    "acuracy_sex_postags = accuracy_score(Ysex_test, log_model_sex_postags.predict(Xsex_test))\n",
    "print ('[Postags Features] Logistic Regression accuracy-Score for GENDER %.3f' % accuracy_sex_postags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Postags Features] GBM accuracy-Score for AGE: 0.409\n",
      "[Postags Features] Logistic Regression accuracy-Score for GENDER 0.591\n"
     ]
    }
   ],
   "source": [
    "# GBM model\n",
    "gbm_model_age_postags = GradientBoostingClassifier()\n",
    "gbm_model_age_postags.fit(Xage_train, Yage_train)\n",
    "accuracy_gbm_age_postags = accuracy_score(Yage_test, gbm_model_age_postags.predict(Xage_test))\n",
    "print ('[Postags Features] GBM accuracy-Score for AGE: %.3f' % accuracy_gbm_age_postags)\n",
    "\n",
    "# SEX\n",
    "gbm_model_sex_postags = LogisticRegression()\n",
    "gbm_model_sex_postags.fit(Xsex_train, Ysex_train)\n",
    "predict = gbm_model_sex_postags.predict(Xsex_test)\n",
    "accuracy_gbm_sex_postags = accuracy_score(Ysex_test, gbm_model_sex_postags.predict(Xsex_test))\n",
    "print ('[Postags Features] Logistic Regression accuracy-Score for GENDER %.3f' % accuracy_gbm_sex_postags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Postags Features] SVC accuracy-Score for AGE: 0.307\n",
      "[Postags Features] SVC accuracy-Score for GENDER: 0.534\n"
     ]
    }
   ],
   "source": [
    "# build SVC model for textual features\n",
    "# AGE\n",
    "svc_model_age_postags = SVC()\n",
    "svc_model_age_postags.fit(Xage_train, Yage_train)\n",
    "accuracy_svc_age_postags = accuracy_score(Yage_test, svc_model_age_postags.predict(Xage_test))\n",
    "print ('[Postags Features] SVC accuracy-Score for AGE: %.3f' % accuracy_svc_age_postags)\n",
    "\n",
    "svc_model_sex_postags = SVC()\n",
    "svc_model_sex_postags.fit(Xsex_train, Ysex_train)\n",
    "accuracy_svc_sex_postags = accuracy_score(Ysex_test, svc_model_sex_postags.predict(Xsex_test))\n",
    "print ('[Postags Features] SVC accuracy-Score for GENDER: %.3f' % accuracy_svc_sex_postags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's combine features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data for AGE\n",
    "X = pd.DataFrame(X)\n",
    "Xage_train, Xage_test, Yage_train, Yage_test = train_test_split(X, Yage, \n",
    "                                                                test_size = 0.20, random_state = 23)\n",
    "\n",
    "# split data for SEX\n",
    "Xsex_train, Xsex_test, Ysex_train, Ysex_test = train_test_split(X, Ysex, \n",
    "                                                                test_size = 0.20, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALL Features] Logistic Regression accuracy-Score for AGE: 0.591\n",
      "[ALL Features] Logistic Regression accuracy-Score for GENDER 0.739\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "# AGE\n",
    "log_model_age_all = LogisticRegression()\n",
    "log_model_age_all.fit(Xage_train, Yage_train)\n",
    "accuracy_age_all = accuracy_score(Yage_test, log_model_age_all.predict(Xage_test))\n",
    "print ('[ALL Features] Logistic Regression accuracy-Score for AGE: %.3f' % accuracy_age_all)\n",
    "\n",
    "# SEX\n",
    "log_model_sex_all = LogisticRegression()\n",
    "log_model_sex_all.fit(Xsex_train, Ysex_train)\n",
    "predict = log_model_sex_all.predict(Xsex_test)\n",
    "acuracy_sex_all = accuracy_score(Ysex_test, log_model_sex_all.predict(Xsex_test))\n",
    "print ('[ALL Features] Logistic Regression accuracy-Score for GENDER %.3f' % acuracy_sex_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALL Features] GBM accuracy-Score for AGE: 0.443\n",
      "[ALL Features] Logistic Regression accuracy-Score for GENDER 0.739\n"
     ]
    }
   ],
   "source": [
    "# GBM model\n",
    "# AGE\n",
    "gbm_model_age_all = GradientBoostingClassifier()\n",
    "gbm_model_age_all.fit(Xage_train, Yage_train)\n",
    "accuracy_gbm_age_all = accuracy_score(Yage_test, gbm_model_age_all.predict(Xage_test))\n",
    "print ('[ALL Features] GBM accuracy-Score for AGE: %.3f' % accuracy_gbm_age_all)\n",
    "\n",
    "# SEX\n",
    "gbm_model_sex_all = LogisticRegression()\n",
    "gbm_model_sex_all.fit(Xsex_train, Ysex_train)\n",
    "predict = gbm_model_sex_all.predict(Xsex_test)\n",
    "accuracy_gbm_sex_all = accuracy_score(Ysex_test, gbm_model_sex_all.predict(Xsex_test))\n",
    "print ('[ALL Features] Logistic Regression accuracy-Score for GENDER %.3f' % accuracy_gbm_sex_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALL Features] SVC accuracy-Score for AGE: 0.352\n",
      "[ALL Features] SVC accuracy-Score for GENDER: 0.523\n"
     ]
    }
   ],
   "source": [
    "# build SVC model for textual features\n",
    "# AGE\n",
    "svc_model_age_all = SVC()\n",
    "svc_model_age_all.fit(Xage_train, Yage_train)\n",
    "accuracy_svc_age_all = accuracy_score(Yage_test, svc_model_age_all.predict(Xage_test))\n",
    "print ('[ALL Features] SVC accuracy-Score for AGE: %.3f' % accuracy_svc_age_all)\n",
    "\n",
    "svc_model_sex_all = SVC()\n",
    "svc_model_sex_all.fit(Xsex_train, Ysex_train)\n",
    "accuracy_svc_sex_all = accuracy_score(Ysex_test, svc_model_sex_all.predict(Xsex_test))\n",
    "print ('[ALL Features] SVC accuracy-Score for GENDER: %.3f' % accuracy_svc_sex_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's delete postags features and see inside inly textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns\n",
    "X_textual = X.drop(['CC', 'CD', 'DT', 'EX', 'FW',\n",
    "       'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT',\n",
    "       'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB',\n",
    "       'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', ',', '.',\n",
    "       ')', '(', ':', '$'], axis = 1)\n",
    "\n",
    "Xage_train, Xage_test, Yage_train, Yage_test = train_test_split(X_textual, Yage, \n",
    "                                                                test_size = 0.20, random_state = 23)\n",
    "\n",
    "# split data for SEX\n",
    "Xsex_train, Xsex_test, Ysex_train, Ysex_test = train_test_split(X_textual, Ysex, \n",
    "                                                                test_size = 0.20, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Textual Features] Logistic Regression accuracy-Score for AGE: 0.602\n",
      "[Textual Features] Logistic Regression accuracy-Score for GENDER 0.795\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "# AGE\n",
    "log_model_age_txt = LogisticRegression()\n",
    "log_model_age_txt.fit(Xage_train, Yage_train)\n",
    "accuracy_age_txt = accuracy_score(Yage_test, log_model_age_txt.predict(Xage_test))\n",
    "print ('[Textual Features] Logistic Regression accuracy-Score for AGE: %.3f' % accuracy_age_txt)\n",
    "\n",
    "# SEX\n",
    "log_model_sex_txt = LogisticRegression()\n",
    "log_model_sex_txt.fit(Xsex_train, Ysex_train)\n",
    "predict = log_model_sex_txt.predict(Xsex_test)\n",
    "acuracy_sex_txt = accuracy_score(Ysex_test, log_model_sex_txt.predict(Xsex_test))\n",
    "print ('[Textual Features] Logistic Regression accuracy-Score for GENDER %.3f' % acuracy_sex_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Textual Features] GBM accuracy-Score for AGE: 0.534\n",
      "[Textual Features] Logistic Regression accuracy-Score for GENDER 0.795\n"
     ]
    }
   ],
   "source": [
    "# GBM model\n",
    "gbm_model_age_txt = GradientBoostingClassifier()\n",
    "gbm_model_age_txt.fit(Xage_train, Yage_train)\n",
    "accuracy_gbm_age_txt = accuracy_score(Yage_test, gbm_model_age_txt.predict(Xage_test))\n",
    "print ('[Textual Features] GBM accuracy-Score for AGE: %.3f' % accuracy_gbm_age_txt)\n",
    "\n",
    "# SEX\n",
    "gbm_model_sex_txt = LogisticRegression()\n",
    "gbm_model_sex_txt.fit(Xsex_train, Ysex_train)\n",
    "predict = gbm_model_sex_txt.predict(Xsex_test)\n",
    "accuracy_gbm_sex_txt = accuracy_score(Ysex_test, gbm_model_sex_txt.predict(Xsex_test))\n",
    "print ('[Textual Features] Logistic Regression accuracy-Score for GENDER %.3f' % accuracy_gbm_sex_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALL Features] SVC accuracy-Score for AGE: 0.352\n",
      "[ALL Features] SVC accuracy-Score for GENDER: 0.523\n"
     ]
    }
   ],
   "source": [
    "# build SVC model for textual features\n",
    "# AGE\n",
    "svc_model_age_txt = SVC()\n",
    "svc_model_age_txt.fit(Xage_train, Yage_train)\n",
    "accuracy_svc_age_txt = accuracy_score(Yage_test, svc_model_age_txt.predict(Xage_test))\n",
    "print ('[ALL Features] SVC accuracy-Score for AGE: %.3f' % accuracy_svc_age_txt)\n",
    "\n",
    "svc_model_sex_txt = SVC()\n",
    "svc_model_sex_txt.fit(Xsex_train, Ysex_train)\n",
    "accuracy_svc_sex_txt = accuracy_score(Ysex_test, svc_model_sex_txt.predict(Xsex_test))\n",
    "print ('[ALL Features] SVC accuracy-Score for GENDER: %.3f' % accuracy_svc_sex_txt)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
