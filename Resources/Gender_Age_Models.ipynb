{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1grams</th>\n",
       "      <th>user_2grams</th>\n",
       "      <th>user_3grams</th>\n",
       "      <th>avr_mentions</th>\n",
       "      <th>avr_punctuation</th>\n",
       "      <th>avr_text_size</th>\n",
       "      <th>avr_starts_with_capital</th>\n",
       "      <th>avr_ends_with_punctuation</th>\n",
       "      <th>avr_capitals</th>\n",
       "      <th>avr_words_count</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.874766</td>\n",
       "      <td>1.036810</td>\n",
       "      <td>1.066692</td>\n",
       "      <td>0.670395</td>\n",
       "      <td>2.661852</td>\n",
       "      <td>100.907532</td>\n",
       "      <td>0.618379</td>\n",
       "      <td>0.517513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044974</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.062386</td>\n",
       "      <td>0.300882</td>\n",
       "      <td>0.830507</td>\n",
       "      <td>0.116462</td>\n",
       "      <td>0.073206</td>\n",
       "      <td>0.957101</td>\n",
       "      <td>0.019846</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.571132</td>\n",
       "      <td>0.647776</td>\n",
       "      <td>0.662023</td>\n",
       "      <td>0.594035</td>\n",
       "      <td>1.014847</td>\n",
       "      <td>26.355495</td>\n",
       "      <td>0.225434</td>\n",
       "      <td>0.220742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.044694</td>\n",
       "      <td>0.200657</td>\n",
       "      <td>0.498240</td>\n",
       "      <td>0.120388</td>\n",
       "      <td>0.077935</td>\n",
       "      <td>0.465992</td>\n",
       "      <td>0.100723</td>\n",
       "      <td>0.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.606500</td>\n",
       "      <td>0.716482</td>\n",
       "      <td>0.733115</td>\n",
       "      <td>0.322451</td>\n",
       "      <td>2.031832</td>\n",
       "      <td>87.791604</td>\n",
       "      <td>0.492247</td>\n",
       "      <td>0.374504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>0.170817</td>\n",
       "      <td>0.457705</td>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>0.663668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.736088</td>\n",
       "      <td>0.911481</td>\n",
       "      <td>0.942441</td>\n",
       "      <td>0.593875</td>\n",
       "      <td>2.650161</td>\n",
       "      <td>102.916575</td>\n",
       "      <td>0.655869</td>\n",
       "      <td>0.513757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060011</td>\n",
       "      <td>0.265686</td>\n",
       "      <td>0.818974</td>\n",
       "      <td>0.080102</td>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.917822</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.981850</td>\n",
       "      <td>1.200095</td>\n",
       "      <td>1.232497</td>\n",
       "      <td>0.889183</td>\n",
       "      <td>3.349250</td>\n",
       "      <td>116.163769</td>\n",
       "      <td>0.784485</td>\n",
       "      <td>0.674474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.403711</td>\n",
       "      <td>1.125513</td>\n",
       "      <td>0.151151</td>\n",
       "      <td>0.094738</td>\n",
       "      <td>1.169578</td>\n",
       "      <td>0.018163</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.758621</td>\n",
       "      <td>4.965517</td>\n",
       "      <td>8.313869</td>\n",
       "      <td>7.055679</td>\n",
       "      <td>174.680894</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>5.735849</td>\n",
       "      <td>0.777027</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>4.159000</td>\n",
       "      <td>2.021255</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_1grams  user_2grams  user_3grams  avr_mentions  avr_punctuation  \\\n",
       "count   436.000000   436.000000   436.000000    436.000000       436.000000   \n",
       "mean      0.874766     1.036810     1.066692      0.670395         2.661852   \n",
       "std       0.571132     0.647776     0.662023      0.594035         1.014847   \n",
       "min       0.000000     0.000000     0.000000      0.000000         0.000000   \n",
       "25%       0.606500     0.716482     0.733115      0.322451         2.031832   \n",
       "50%       0.736088     0.911481     0.942441      0.593875         2.650161   \n",
       "75%       0.981850     1.200095     1.232497      0.889183         3.349250   \n",
       "max       4.137931     4.758621     4.965517      8.313869         7.055679   \n",
       "\n",
       "       avr_text_size  avr_starts_with_capital  avr_ends_with_punctuation  \\\n",
       "count     436.000000               436.000000                 436.000000   \n",
       "mean      100.907532                 0.618379                   0.517513   \n",
       "std        26.355495                 0.225434                   0.220742   \n",
       "min         0.000000                 0.000000                   0.000000   \n",
       "25%        87.791604                 0.492247                   0.374504   \n",
       "50%       102.916575                 0.655869                   0.513757   \n",
       "75%       116.163769                 0.784485                   0.674474   \n",
       "max       174.680894                 0.999000                   1.000000   \n",
       "\n",
       "       avr_capitals  avr_words_count     ...              WP         WP$  \\\n",
       "count           436       436.000000     ...      436.000000  436.000000   \n",
       "mean              0         0.049918     ...        0.044974    0.000222   \n",
       "std               0         0.093549     ...        0.033654    0.001027   \n",
       "min               0         0.000000     ...        0.000000    0.000000   \n",
       "25%               0         0.011482     ...        0.018887    0.000000   \n",
       "50%               0         0.020000     ...        0.042000    0.000000   \n",
       "75%               0         0.039494     ...        0.068000    0.000000   \n",
       "max               0         1.111111     ...        0.262295    0.013699   \n",
       "\n",
       "              WRB           ,           .           )           (           :  \\\n",
       "count  436.000000  436.000000  436.000000  436.000000  436.000000  436.000000   \n",
       "mean     0.062386    0.300882    0.830507    0.116462    0.073206    0.957101   \n",
       "std      0.044694    0.200657    0.498240    0.120388    0.077935    0.465992   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.028094    0.170817    0.457705    0.034450    0.021984    0.663668   \n",
       "50%      0.060011    0.265686    0.818974    0.080102    0.047273    0.917822   \n",
       "75%      0.091000    0.403711    1.125513    0.151151    0.094738    1.169578   \n",
       "max      0.252000    1.625000    5.735849    0.777027    0.403000    4.159000   \n",
       "\n",
       "                $          ''  \n",
       "count  436.000000  436.000000  \n",
       "mean     0.019846    0.000307  \n",
       "std      0.100723    0.001063  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.007230    0.000000  \n",
       "75%      0.018163    0.000000  \n",
       "max      2.021255    0.010000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_features.csv', sep='\\t', index_col=0)\n",
    "data = pd.DataFrame(data)\n",
    "del data['Unnamed: 0.1']\n",
    "del data['Unnamed: 0.1.1']\n",
    "\n",
    "del data['user']\n",
    "data = data.fillna(0)\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1grams</th>\n",
       "      <th>user_2grams</th>\n",
       "      <th>user_3grams</th>\n",
       "      <th>avr_mentions</th>\n",
       "      <th>avr_punctuation</th>\n",
       "      <th>avr_text_size</th>\n",
       "      <th>avr_starts_with_capital</th>\n",
       "      <th>avr_ends_with_punctuation</th>\n",
       "      <th>avr_capitals</th>\n",
       "      <th>avr_words_count</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>2.148148</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.563636</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.753260</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.034102</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>3.477432</td>\n",
       "      <td>103.528586</td>\n",
       "      <td>0.676028</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>1.207207</td>\n",
       "      <td>4.055055</td>\n",
       "      <td>135.671672</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.723724</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>1.231231</td>\n",
       "      <td>0.029029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>0.302949</td>\n",
       "      <td>1.938338</td>\n",
       "      <td>82.536193</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>0.319035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_1grams  user_2grams  user_3grams  avr_mentions  avr_punctuation  \\\n",
       "0     0.425926     0.481481     0.546296      0.685185         2.148148   \n",
       "1     1.300000     1.472727     1.500000      1.200000         2.563636   \n",
       "2     0.753260     1.003009     1.034102      0.494483         3.477432   \n",
       "3     0.615616     0.824825     0.869870      1.207207         4.055055   \n",
       "4     0.695710     0.813673     0.820375      0.302949         1.938338   \n",
       "\n",
       "   avr_text_size  avr_starts_with_capital  avr_ends_with_punctuation  \\\n",
       "0      74.666667                 0.796296                   0.240741   \n",
       "1      88.636364                 0.236364                   0.763636   \n",
       "2     103.528586                 0.676028                   0.563691   \n",
       "3     135.671672                 0.853854                   0.653654   \n",
       "4      82.536193                 0.190349                   0.319035   \n",
       "\n",
       "   avr_capitals  avr_words_count ...        WP  WP$       WRB         ,  \\\n",
       "0             0         0.064815 ...  0.000000    0  0.000000  0.111111   \n",
       "1             0         0.172727 ...  0.072727    0  0.000000  0.345455   \n",
       "2             0         0.019057 ...  0.069208    0  0.057172  0.274824   \n",
       "3             0         0.017017 ...  0.094094    0  0.090090  0.311311   \n",
       "4             0         0.006702 ...  0.018767    0  0.056300  0.123324   \n",
       "\n",
       "          .         )         (         :         $  ''  \n",
       "0  0.888889  0.037037  0.037037  0.722222  0.000000   0  \n",
       "1  1.109091  0.090909  0.036364  0.727273  0.000000   0  \n",
       "2  1.338014  0.070211  0.034102  0.996991  0.000000   0  \n",
       "3  1.723724  0.030030  0.013013  1.231231  0.029029   0  \n",
       "4  0.428954  0.120643  0.069705  0.906166  0.013405   0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model for age\n",
    "age_data = data\n",
    "target = age_data['age']\n",
    "del age_data['age']\n",
    "del age_data['sex']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(age_data, target, test_size = 0.20, random_state = 23)\n",
    "\n",
    "age_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.431818181818\n"
     ]
    }
   ],
   "source": [
    "#build logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, Y_train)\n",
    "print(log_reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306818181818\n"
     ]
    }
   ],
   "source": [
    "#build SVM model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "print(svm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.420454545455\n",
      "[ 0.01529233  0.00472322  0.00488547  0.02862924  0.01051755  0.03624473\n",
      "  0.04105491  0.02480711  0.          0.01963599  0.01800934  0.01076885\n",
      "  0.02033816  0.01652998  0.01670774  0.02790722  0.02807344  0.0323521\n",
      "  0.02244662  0.0116293   0.00767798  0.0106827   0.01502538  0.03505617\n",
      "  0.09411764  0.00814018  0.00994536  0.00275495  0.01200407  0.01633635\n",
      "  0.01748106  0.03905664  0.01182446  0.01181137  0.00953561  0.00706217\n",
      "  0.00926976  0.00602556  0.02995658  0.00410524  0.00913799  0.01639755\n",
      "  0.0247404   0.01069134  0.02083272  0.00223463  0.01427879  0.02370086\n",
      "  0.01712212  0.04740678  0.01735182  0.02078068  0.02031964  0.00658211]\n",
      "0.018518518518518517\n",
      "Index(['user_2grams', 'avr_mentions', 'avr_punctuation', 'avr_text_size',\n",
      "       'avr_ends_with_punctuation', 'vocabulary_richness', 'DT', 'EX', 'FW',\n",
      "       'IN', 'MD', 'NN', 'PRP$', 'UH', 'VBN', 'VBZ', 'WP$', ',', ')', '('],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/pandas/core/index.py:1160: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 56 but corresponding boolean dimension is 54\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "source": [
    "#build GBM model\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, Y_train)\n",
    "print(gbm.score(X_test, Y_test))\n",
    "print(gbm.feature_importances_)\n",
    "print(1 / len(gbm.feature_importances_ ))\n",
    "print(data.columns[gbm.feature_importances_ >= 0.0185])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_data = data[['user_2grams', 'avr_mentions', 'avr_punctuation', 'avr_text_size',\n",
    "       'avr_ends_with_punctuation', 'vocabulary_richness', 'DT', 'EX', 'FW',\n",
    "       'IN', 'MD', 'NN', 'PRP$', 'UH', 'VBN', 'VBZ', 'WP$', ',', ')', '(']]\n",
    "target = data['age']\n",
    "age_data.head()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(age_data, target, test_size = 0.20, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log scort: 0.397727272727\n",
      "SVM score: 0.306818181818\n",
      "GBM score: 0.397727272727\n"
     ]
    }
   ],
   "source": [
    "#build logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, Y_train)\n",
    "print('Log scort: ' + str(log_reg.score(X_test, Y_test)))\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "print('SVM score: ' + str(svm.score(X_test, Y_test)))\n",
    "\n",
    "#build GBM model\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, Y_train)\n",
    "print('GBM score: ' + str(gbm.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbm, 'gbm_model.pkl', compress = 9)\n",
    "joblib.dump(svm, 'svm_model.pkl', compress = 9)\n",
    "joblib.dump(log_reg, 'log_model.pkl', compress = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM: ['25-34\\r\\n']\n",
      "SVM: ['35-49\\r\\n']\n",
      "LOG REG: ['35-49\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 1]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM: ['25-34\\r\\n']\n",
      "SVM: ['35-49\\r\\n']\n",
      "LOG REG: ['35-49\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 0]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1grams</th>\n",
       "      <th>user_2grams</th>\n",
       "      <th>user_3grams</th>\n",
       "      <th>avr_mentions</th>\n",
       "      <th>avr_punctuation</th>\n",
       "      <th>avr_text_size</th>\n",
       "      <th>avr_starts_with_capital</th>\n",
       "      <th>avr_ends_with_punctuation</th>\n",
       "      <th>avr_capitals</th>\n",
       "      <th>avr_words_count</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>)</th>\n",
       "      <th>(</th>\n",
       "      <th>:</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>2.148148</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.563636</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.753260</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.034102</td>\n",
       "      <td>0.494483</td>\n",
       "      <td>3.477432</td>\n",
       "      <td>103.528586</td>\n",
       "      <td>0.676028</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.070211</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>1.207207</td>\n",
       "      <td>4.055055</td>\n",
       "      <td>135.671672</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>0.653654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.723724</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>1.231231</td>\n",
       "      <td>0.029029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.820375</td>\n",
       "      <td>0.302949</td>\n",
       "      <td>1.938338</td>\n",
       "      <td>82.536193</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>0.319035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>0.428954</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_1grams  user_2grams  user_3grams  avr_mentions  avr_punctuation  \\\n",
       "0     0.425926     0.481481     0.546296      0.685185         2.148148   \n",
       "1     1.300000     1.472727     1.500000      1.200000         2.563636   \n",
       "2     0.753260     1.003009     1.034102      0.494483         3.477432   \n",
       "3     0.615616     0.824825     0.869870      1.207207         4.055055   \n",
       "4     0.695710     0.813673     0.820375      0.302949         1.938338   \n",
       "\n",
       "   avr_text_size  avr_starts_with_capital  avr_ends_with_punctuation  \\\n",
       "0      74.666667                 0.796296                   0.240741   \n",
       "1      88.636364                 0.236364                   0.763636   \n",
       "2     103.528586                 0.676028                   0.563691   \n",
       "3     135.671672                 0.853854                   0.653654   \n",
       "4      82.536193                 0.190349                   0.319035   \n",
       "\n",
       "   avr_capitals  avr_words_count ...         WP  WP$       WRB         ,  \\\n",
       "0             0         0.064815 ...   0.000000  0.0  0.000000  0.111111   \n",
       "1             0         0.172727 ...   0.072727  0.0  0.000000  0.345455   \n",
       "2             0         0.019057 ...   0.069208  0.0  0.057172  0.274824   \n",
       "3             0         0.017017 ...   0.094094  0.0  0.090090  0.311311   \n",
       "4             0         0.006702 ...   0.018767  0.0  0.056300  0.123324   \n",
       "\n",
       "          .         )         (         :         $   ''  \n",
       "0  0.888889  0.037037  0.037037  0.722222  0.000000  0.0  \n",
       "1  1.109091  0.090909  0.036364  0.727273  0.000000  0.0  \n",
       "2  1.338014  0.070211  0.034102  0.996991  0.000000  0.0  \n",
       "3  1.723724  0.030030  0.013013  1.231231  0.029029  0.0  \n",
       "4  0.428954  0.120643  0.069705  0.906166  0.013405  0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model for sex\n",
    "sex_data = data\n",
    "target = sex_data['sex']\n",
    "del sex_data['age']\n",
    "del sex_data['sex']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(age_data, target, test_size = 0.20, random_state = 23)\n",
    "\n",
    "sex_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590909090909\n"
     ]
    }
   ],
   "source": [
    "#build logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, Y_train)\n",
    "print(log_reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534090909091\n"
     ]
    }
   ],
   "source": [
    "#build SVM model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "print(svm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659090909091\n"
     ]
    }
   ],
   "source": [
    "#build GBM model\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, Y_train)\n",
    "print(gbm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must  match the input. Model n_features is 11 and  input n_features is 5 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-342c7809f1b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m\"GBM: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m\"SVM: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m\"LOG REG: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \"\"\"\n\u001b[1;32m-> 1498\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1499\u001b[0m         \u001b[0mdecisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1455\u001b[0m         \"\"\"\n\u001b[0;32m   1456\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         \u001b[1;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[1;31m# not doing input validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_init_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[1;34m\"\"\"Check input and compute prediction of ``init``. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
      "\u001b[1;32mC:\\Users\\Kseniya.Buraya\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    374\u001b[0m                              \u001b[1;34m\" match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                              \u001b[1;34m\" input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must  match the input. Model n_features is 11 and  input n_features is 5 "
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 1]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM: ['MALE']\n",
      "SVM: ['FEMALE']\n",
      "LOG REG: ['FEMALE']\n"
     ]
    }
   ],
   "source": [
    "features = [4, 2, 0, 0, 0]\n",
    "features = np.array(features).reshape(1, -1)\n",
    "print ( \"GBM: \" + str(gbm.predict(features)))\n",
    "print ( \"SVM: \" + str(svm.predict(features)))\n",
    "print ( \"LOG REG: \" + str(log_reg.predict(features)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
